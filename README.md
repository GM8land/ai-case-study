# CASE STUDY - Diffbot

## Overview and Origin

Diffbot was Founded in 2012 by Mike Tung (CEO). As a graduate student studying Artificial Intelligence at Stanford circa 2011, Mike Tung was working on an algorithm to understand human language, which would require an extremely large model to accomplish. The most comprehensive source of data that could be used to train a model is the World Wide Web, but the solution to extracting and training the vast amount of unstructured data would require automation.  Around that time, he was exposed to Computer Vision (Image Net) and saw the potential of using Machine Learning to train large models. He joined Stanford's StartX incubator and began working on a solution to query, structure, and synthesize the data of the entire World Wide Web. The first round of startup funding ($2M) was received in 2012 through StartX, followed by 3 subsequent rounds of Venture Capital funding totaling $13M. 

## Mission Statement

>Diffbot’s Mission is to accelerate the advent of intelligent systems by building the first autonomous system capable of synthesizing human knowledge. We crawl the entire public web and operate the world's largest automated Knowledge Graph.
>https://www.diffbot.com/company/

## Business Activities

Diffbot’s business is focused on Market Intelligence, Web Data Extraction, and Content Aggregation. The company provides knowledge services to more than 400 businesses worldwide by making large amounts of structured granular data available to customers through its APIs. It accomplishes this via a large-scale automated crawler that scans the Web, utilizes Machine Learning, Natural Language Processing, and Computer Vision technologies to extract data from various unstructured sources, and provides refreshed data to their daily. As of 2022, Diffbot's Knowledge Graph contains 5.9 billion discrete entities with an average of 31 facts available for each.  

Key industries in Diffbot’s customer base include Finance, Marketing, Media, and Technology. Notable large enterprise customers of Diffbot include Dow Jones, FINRA, Cisco, eBay, NBC, The New York Times, and AstraZeneca.   

## Trends and Developments

- Advances in Machine Learning have led to improved algorithms for both data extraction from web pages and the creation of more accurate and comprehensive knowledge graphs.

- Semantic web technologies such as RDF (Resource Description Framework) and SPARQL (SPARQL Protocol and RDF Query Language are allowing for more effective integration and analysis of web data.

- The concept of "Linked Data" has gained prominence and has led to the creation of large-scale knowledge graphs that connect diverse sources of information.

- An increased emphasis on real-time web crawling has evolved in response to the major growth of social media and availability of real-time data, requiring development of new techniques to extract and update information from constantly evolving web sources. 

- Knowledge graphs have become an essential component of many AI systems as companies utilize structured knowledge graphs to enhance their search engines, virtual assistant platforms, and recommendation systems.

- There is a growing emphasis on ensuring responsible data acquisition, compliance with regulations, and addressing concerns related to data ownership and consent.

## Competitive Landscape

Major companies in this field include Google, Microsoft (Bing), Octopus Data, Scrapinghub, ParseHub, Import.io, Bright Data, Oxylabs, and Smartproxy 
While Google and Microsoft are also crawling and structuring the web’s data, Diffbot leverages a significant advantage among its main competitors by developing and maintaining the world’s largest knowledge graph to collect and structure data autonomously in real-time. Its automation allows it to parse billions of datapoints daily, a scale that is not feasible for most businesses. Additionally, it is the only one which allows all data to be downloaded and integrated, and because it maintains its own hardware infrastructure, customers can access large amounts of Machine Learning and data processing much more efficiently and cheaply. 

## Business Impact and Results

The structured data available on Diffbot’s Knowledge Graph is used by more than 400 companies to improve market intelligence and make better-informed business decisions, obtain valuable customer insights to deepen customer engagement, and streamline content creation and curation. In addition to the standard metrics common to all businesses, examples of the functional metrics that companies in this field use to measure success include Accuracy, Coverage, Speed Data Freshness, Usability, and Compliance/Governance. Specific functional metrics for Diffbot are not available. Diffbot reported revenues of $2.3M in 2023 vs $1.9M in 2021, a YOY increase of 11.8%.  and the company has a 4.9 out of 5 stars based on 29 verified reviews on g2.com.

## Recommendation

Diffbot uses the web as the source of unstructured data for its knowledge graph and services, and excels at this by keeping their core mission simple. In order to build on their competitive advantage without significantly changing that scope, I would recommend exploring the integration and synthesis of additional structured and unstructured data in the U.S. Census Bureau's database into their Knowledge Graph.  

Based on Diffbot's customer industries, there are opportunities to expand and deepen the data in their Knowledge Graph with census data. The U.S. Census Bureau makes a variety of data sources and types available in the public domain, including raw data, maps, and tables. While many businesses and researchers already access and analyze this data on a smaller scale, Diffbot's unique advantage is that they already deliver the largest synthesis of web data. A large scale synthesis of census data into the existing Knowledge Graph would unlock new insights and increase Diffbot's market share in this field. The core technologies required for this (e.g., Machine Learning, Computer Vision, Knowledge Graphs, APIs) are already in use by Diffbot, but scaling up of automation and processing resources would be required.  

## Sources

https://www.diffbot.com/
https://techcrunch.com/2012/05/31/diffbot-raises-2-million-seed-round-for-web-content-extraction-technology/
https://youtu.be/bVcKUy5jFwU?si=Y8QiP2gfSC10G
https://stackshare.io/stackups/diffbot-vs-octoparse
https://tracxn.com/d/companies/diffbot/___8Nja_cRIbVHa-LtWmj9igj6aqUQY82Q23PamibaRz4/competitors
https://www.openpr.com/news/3389420/web-scraping-software-market-to-get-an-explosive-growth-octopus
https://getlatka.com/companies/diffbot
https://www.diffbot.com/company/news/20160211.html
https://blog.diffbot.com/benchmarking-diffbot-knowledge-graph-versus-google-knowledge-graph/
https://www.linkedin.com/posts/miketung_knowledge-graph-technology-showcase-honest-activity-6942864515315245056-ZSyY?trk=public_profile_like_view
https://www.g2.com/products/diffbot/reviews
OpenAI (2024). “What are the major trends of the past 10 years in the field of web crawling and knowledge graphs” [GPT Assistant response] Retrieved May 7, 2024 from  https://www.openai.com/gpt-4/ 
